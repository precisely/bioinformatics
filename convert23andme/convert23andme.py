'''
convert23andme: Python module for converting 23andMe raw data to VCF format

Provided a 23andMe data file as input, along with a
specially-formatted human genome sequence file and a human genome gene
coordinates file, this module will convert the data into a
Precise.ly-formatted VCF file. See the README for more information on
obtaining the human genome sequence and gene coordinate files.

TODOs:
* In a future version, we need to dispatch on file metadata to
  automagically select the correct version of the reference genome.

## Functions removed:
After tag v0.1, I removed the following functions that were no longer needed:
* gen_svn_genotype_string
* gen_variant_call_struct
* gen_genotype_summary_str
* print_vcf_to_ga4gh_json_file
* predict_23andMe_chip_version
* agumented_vcf_record

'''


### Import statements:
from pysam import VariantFile
import subprocess, sys, json, shutil, os
from time import time
from datetime import datetime
import tempfile
import gzip
import logging, traceback
import tempfile
import boto3


### Global Definitions:

## Hash that maps genome version and chromosome ID to NCBI Accession number:
human_genome_accessions = {
    '37': {
        '1':  'NC_000001.10',
        '2':  'NC_000002.11',
        '3':  'NC_000003.11',
        '4':  'NC_000004.11',
        '5':  'NC_000005.9',
        '6':  'NC_000006.11',
        '7':  'NC_000007.13',
        '8':  'NC_000008.10',
        '9':  'NC_000009.11',
        '10': 'NC_000010.10',
        '11': 'NC_000011.9',
        '12': 'NC_000012.11',
        '13': 'NC_000013.10',
        '14': 'NC_000014.8',
        '15': 'NC_000015.9',
        '16': 'NC_000016.9',
        '17': 'NC_000017.10',
        '18': 'NC_000018.9',
        '19': 'NC_000019.9',
        '20': 'NC_000020.10',
        '21': 'NC_000021.8',
        '22': 'NC_000022.10',
        'X':  'NC_000023.10',
        'Y':  'NC_000024.9',
        'MT': 'NC_012920.1'
        }
    }


def parse_23andMe_file(genotype_23andme_path):
    '''Parse out the creation date and the genome assembly version
    from a 23andMe raw data file, and the number of SNPs, and return as a list.'''

    snp_counts = 0

    with open(genotype_23andme_path) as file_23andMe:

        for line in file_23andMe:

            if line.startswith('# This data file generated by 23andMe at:'):
                timestamp_str = line.rstrip().split(': ')[1]
                datetime_object = datetime.strptime(timestamp_str, '%c')

            if line.startswith('# More information on reference human assembly build'):
                genome_version = line.rstrip().split('build ')[1].split(' ')[0]

            if not line.startswith('#'):
                snp_counts += 1

    return [datetime_object, genome_version, snp_counts]


def convert_23andme_bcf(genotype_23andme_fileName,
                            raw_23andme_file,
                            ref_human_genome_path,
                            annotate_file_path,
                            output_bucket):
    '''
    Main function for converting 23andMe raw data file into a VCF
    file. Returns a string path to the output file location.
    '''

    ## Definitions:
    [sample_id, file_md5_hash_value] = genotype_23andme_fileName.split('/')[-1].split('_')

    tmp_dir = tempfile.mkdtemp()

    logging.info("Working directory is : " + tmp_dir)

    temp_vcf_file     = tmp_dir + '/' + sample_id + '_temp.vcf'

    vcf_aug_file = tmp_dir + '/' + sample_id + '.vcf.gz'

    ## Command for using bcftools for converting 23&Me tab-delimited
    ## genotype files to VCF format:

    # subprocess.check_output([
    #     'bcftools',
    #     'convert',
    #     '--tsv2vcf',
    #     genotype_23andme_path,
    #     '-f',
    #     ref_human_genome_path,
    #     '-s',
    #     sample_id,
    #     '-Ob',
    #     '-o',
    #     temp_bcf_file])

    ## Get 23andMe raw file stats:
    [ processing_datetime,
          genome_version,
          snp_count        ] = parse_23andMe_file(raw_23andme_file)


    ## Make header file

    with open(tmp_dir + '/header-file.txt','w') as header_file:
        print >> header_file, "##INFO=<ID=GENE,Number=1,Type=String,Description=\"Gene name from UCSC Genome Browser BED file\">"

    subprocess.check_output(' '.join(['bcftools',
                                        'convert',
                                        '--tsv2vcf',
                                        raw_23andme_file,
                                        '-f',
                                        ref_human_genome_path,
                                        '-s',
                                        sample_id,
                                        '-Ob',
                                        '|',
                                        'bcftools',
                                        'annotate',
                                        '-a',
                                        annotate_file_path,
                                        '-c CHROM,FROM,TO,GENE',
                                        '-h',
                                        tmp_dir + '/header-file.txt',
                                        '-Ov',
                                        '-o',
                                        temp_vcf_file,
                                        '-']),
                                shell=True)



    augmented_vcf_file(temp_vcf_file,
                           vcf_aug_file,
                           tmp_dir,
                           sample_id,
                           processing_datetime,
                           genome_version,
                           snp_count,
                           ref_human_genome_path)

    vcf_aug_base_file_name = sample_id + '.vcf.gz'

    logging.info('Uploading file to target bucket.')
    target_bucket.upload_file(vcf_aug_file, vcf_aug_base_file_name)

    logging.info('Deleting temp directory.')
    shutil.rmtree(tmp_dir)

    logging.info('Task complete. File available @ s3://' + output_bucket + '/' + vcf_aug_base_file_name)


def augmented_vcf_file(vcf_file,
                           vcf_aug_file,
                           tmp_dir,
                           sample_id,
                           date_23andMe_process,
                           genome_version,
                           snp_count,
                           reference_file_name):
    '''
    This helper function writes out the parsed data into VCF format.
    '''

    vcf_in  = VariantFile(vcf_file)

    ## Add additional header lines to the VCF:

    new_header = vcf_in.header
    new_header.add_line('##fileDate='                  + datetime.strftime(datetime.now(), '%c')      )
    new_header.add_line('##23andMeSampleID='           + sample_id                                    )
    new_header.add_line('##23andMeProcessDate='        + datetime.strftime(date_23andMe_process, '%c'))
    new_header.add_line('##23andMeHumanGenomeVersion=' + genome_version                               )
    new_header.add_line('##23andmeSNPcount='           + str(snp_count)                               )
    new_header.add_line('##reference=file://'          + reference_file_name                          )
    new_header.add_line('##FILTER=<ID=NOT_DETERMINED,Description="Genotype not determined by 23andMe">')

    ##vcf_out = VariantFile(vcf_aug_file, 'w', header=new_header)

    temp_header_file = tmp_dir + '/header_temp.vcf'

    with open(temp_header_file, 'w') as header_file:

        logging.info('PySAM is buggy, returning an extra space character when printing the header object. Removing.')
        print >> header_file, new_header,


    with gzip.open(vcf_aug_file, 'w') as vcf_out:

        with open(temp_header_file, 'r') as header_file:
            for line in header_file:
                if line.startswith('#'):
                    print >> vcf_out, line.rstrip()


        with open(vcf_file, 'r') as vcf_in:

            for line in vcf_in:

                if not line.startswith('#'):

                    fields = line.rstrip().split('\t')

                    ## Modify FILTER values
                    if fields[9] == '.':
                        fields[6] = 'NOT_DETERMINED'
                    else:
                        fields[6] = 'PASS'

                    print >> vcf_out, '\t'.join(fields)


    logging.info('Printed augmented VCF file to: ' + vcf_aug_file)
    return




## Obtain variable definitions from the environment:
if __name__ == "__main__":

    genotype_23andme_raw_bucketName = sys.argv[1]
    genotype_23andme_raw_fileName   = sys.argv[2]
    ref_human_genome_path           = sys.argv[3]
    annotate_file_path              = sys.argv[4]
    genotype_vcf_target_bucketName  = sys.argv[5]
    region_name                     = sys.argv[6]
    aws_access_key_id               = sys.argv[7]
    aws_secret_access_key           = sys.argv[8]

    try:
        s3 = boto3.resource(
                's3',
                aws_access_key_id = aws_access_key_id,
                aws_secret_access_key = aws_secret_access_key,
                region_name = region_name
            )

        raw_bucket = s3.Bucket(genotype_23andme_raw_bucketName)
        target_bucket = s3.Bucket(genotype_vcf_target_bucketName)

        _, tmp_23andme_file = tempfile.mkstemp()

        # Download file to a temporary file-like object
        # This is a managed transfer, which will perform a multipart download in multiple threads if necessary
        with open(tmp_23andme_file, 'wb') as data:
            raw_bucket.download_fileobj(genotype_23andme_raw_fileName, data)

        convert_23andme_bcf(genotype_23andme_raw_fileName,
                                tmp_23andme_file,
                                ref_human_genome_path,
                                annotate_file_path,
                                genotype_vcf_target_bucketName)

        os.remove(tmp_23andme_file) # remove the temporary data file

    except:
        ## Trap any errors when running as script, and report the
        ## stack trace:
        [sample_id, file_md5_hash_value] = genotype_23andme_raw_fileName.split('/')[-1].split('_')

        _, tmp_error_log_file = tempfile.mkstemp()

        with open(tmp_error_log_file, 'w') as error_file:

            print >> error_file, "Exception type:", sys.exc_info()[0]
            print >> error_file, "Exception Args:", sys.exc_info()[1]
            print >> error_file, traceback.format_exc()

        target_bucket.upload_file(tmp_error_log_file, 'error_logs/' + sample_id + '.error')
        logging.error('Error log uploaded @ s3://' + genotype_vcf_target_bucketName + '/error_logs/' + sample_id + '.error')

        os.remove(tmp_error_log_file)   # remove the temporary error file
        sys.exit(1)
